{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"sketch_clustering.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"16rMEUs19cP0bIFO1dcUNWwfpGJhk95j2","authorship_tag":"ABX9TyOIDDPqJT5Ia7Dtat64W5dk"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UTb2RneWn5dp"},"source":["### 초기설정"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VWB08whFNasE","executionInfo":{"status":"ok","timestamp":1626833922820,"user_tz":-540,"elapsed":5099,"user":{"displayName":"성균관대학교조혜원","photoUrl":"","userId":"03834350891639842364"}},"outputId":"b72f81b0-ea09-4a62-e8dc-f53c1e242427"},"source":["!pip install efficientnet_pytorch"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting efficientnet_pytorch\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n","Building wheels for collected packages: efficientnet-pytorch\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=4d47fc7fc797f440cbbf7a66eba863a6dc066858a1587a36fbef6f9647a0518d\n","  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n","Successfully built efficientnet-pytorch\n","Installing collected packages: efficientnet-pytorch\n","Successfully installed efficientnet-pytorch-0.7.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T-YX_2ITJajI","executionInfo":{"status":"ok","timestamp":1626834272008,"user_tz":-540,"elapsed":3870,"user":{"displayName":"성균관대학교조혜원","photoUrl":"","userId":"03834350891639842364"}}},"source":["from efficientnet_pytorch import EfficientNet\n","from sklearn.cluster import KMeans\n","from sklearn.decomposition import PCA\n","# from keras.applications.vgg16 import VGG16 \n","# from keras.models import Model\n","# from keras.applications.vgg16 import preprocess_input \n","import os\n","import logging\n","import torch\n","import pickle\n","from tqdm import tqdm\n","from torchvision import transforms\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"XYnJ5cW0n2Zq","executionInfo":{"status":"ok","timestamp":1626834278037,"user_tz":-540,"elapsed":273,"user":{"displayName":"성균관대학교조혜원","photoUrl":"","userId":"03834350891639842364"}}},"source":["#dataset path\n","data_path = '/content/drive/MyDrive/Colab/Sketch_RNN_Together/Dataset/test'\n","#feature path\n","feat_path = \"/content/drive/MyDrive/Colab/Sketch_RNN/torch_sketch/features.npy\"\n","#filename path\n","filename_path = \"/content/drive/MyDrive/Colab/Sketch_RNN/torch_sketch/filenames.npy\"\n","#cluster_list\n","cluster_list_path = '/content/drive/MyDrive/Colab/Sketch_RNN/torch_sketch/cluster_list.txt'\n","cluster_list = open(cluster_list_path , 'r').read().split('\\n')\n","\n","# p = r\"/content/drive/MyDrive/Colab/Sketch_RNN/torch_sketch/sktch_log.pkl\""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"aMgSx0PXJenF"},"source":["#make data_list : .npy files\n","os.chdir(data_path)\n","data_list = []\n","with os.scandir(data_path) as files:\n","    for file in files:\n","        if file.name.endswith('.npy'):\n","            data_list.append(file.name) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wLvUDAarsEIv"},"source":["### Feature Extraction"]},{"cell_type":"code","metadata":{"cellView":"code","id":"IjCYRALgNNGN"},"source":["#transform\n","tfms = transforms.Compose([transforms.Resize(224), transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n","\n","def feature_extraction(image, model):\n","    img = tfms(Image.fromarray(image.reshape(28,28)).convert(\"RGB\")).unsqueeze(0)\n","    features = model.extract_features(img)\n","    return features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A1adKg0aJ15K","executionInfo":{"status":"ok","timestamp":1626716434732,"user_tz":-540,"elapsed":5126776,"user":{"displayName":"성균관대학교조혜원","photoUrl":"","userId":"03834350891639842364"}},"outputId":"29fcd744-4a04-4c32-d457-40437ed88ec2"},"source":["#efficientNet\n","#feature extraction\n","model = EfficientNet.from_pretrained('efficientnet-b0')\n","data = {}\n","cluster_list = []\n","for npy in tqdm(data_list[-10:]):\n","    cluster_list.append(npy.split('.')[0])\n","    image_list = np.load(npy) \n","    for i, image in enumerate(image_list[:2000]):\n","      # try:\n","        feat = feature_extraction(image, model)\n","        feat = feat.detach().numpy().reshape(-1)\n","        name = npy.split('.')[0] + '_' + str(i)\n","        data[name] = (feat)\n","        if(i % 200 == 0):\n","          np.save(feat_path, np.array(list(data.values())))\n","          np.save(filename_path, np.array(list(data.keys())))\n","      # except:\n","      #   with open(p,'wb') as file:\n","      #     pickle.dump(data,file)\n","\n","np.save(feat_path, np.array(list(data.values())))\n","np.save(filename_path, np.array(list(data.keys())))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loaded pretrained weights for efficientnet-b0\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [1:24:34<00:00, 507.47s/it]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"EXSd3JgIsJF4"},"source":["### Dimension Reduction"]},{"cell_type":"code","metadata":{"id":"IoX_wOe6dJWz"},"source":["#PCA\n","# feat = np.load(feat_path)\n","# from sklearn.decomposition import PCA\n","# pca = PCA(n_components=2, random_state=0)\n","# pca.fit(feat)\n","# x = pca.transform(feat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MI4Xn9lB-Zse"},"source":["#TSNE\n","feat = np.load(feat_path)\n","from sklearn.manifold import TSNE\n","tsne = TSNE(n_components=2, init='pca', random_state=0)\n","x = tsne.fit_transform(feat)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M8kQROFssL5o"},"source":["### Clustering"]},{"cell_type":"code","metadata":{"id":"FvIUYj-ksubr"},"source":["def clustering_method(cmd, cluster_num, input):\n","  if cmd == 'kmeans':\n","    from sklearn.cluster import KMeans\n","    kmeans = KMeans(n_clusters=cluster_num, n_jobs=-1, random_state = 0)\n","    kmeans.fit(input)\n","    return kmeans.labels_\n","\n","  elif cmd == 'minibatch':\n","    from sklearn.cluster import MiniBatchKMeans\n","    mb_kmeans = MiniBatchKMeans(n_clusters=cluster_num,random_state=0, batch_size=6)\n","    mb_kmeans.fit(input)\n","    return mb_kmeans.labels_\n","\n","  elif cmd == 'dbscan':\n","    from sklearn.cluster import DBSCAN\n","    dbscan = DBSCAN(eps=1.8, min_samples=2)\n","    dbscan.fit(input)\n","    return dbscan.labels_\n","  elif cmd == 'birch':\n","    from sklearn.cluster import Birch\n","    brc = Birch(n_clusters=cluster_num)\n","    brc.fit(input)\n","    return brc.labels_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"65BJIaq-vGtO"},"source":["labels = clustering_method('birch', len(cluster_list), x)\n","import plotly.express as px\n","from plotly.offline import plot\n","fig = px.scatter(x, x=0, y=1, color=labels)\n","plot(fig)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HmWsnNIpvIVF"},"source":["### Testing"]},{"cell_type":"markdown","metadata":{"id":"7ezSQp7UzktV"},"source":[""]},{"cell_type":"code","metadata":{"id":"yFPSTHkadqJE"},"source":["filenames = np.load(filename_path)\n","groups = {}\n","# holds the cluster id and the images { id: [images] }\n","for f, cluster in zip(filenames, labels):\n","    if cluster not in groups.keys():\n","        groups[cluster] = []\n","        groups[cluster].append(f)\n","    else:\n","        groups[cluster].append(f)\n","\n","#make cluster_dict for calculate acc\n","cluster_dict = {}\n","for cluster in groups:\n","  image_count = []\n","  image_name = []\n","  for image in groups[cluster]:\n","    image_name.append(image.split('_')[0])\n","  for name in cluster_list:\n","    image_count.append(image_name.count(name))\n","\n","  cluster_dict[cluster] = cluster_list[image_count.index(max(image_count))]\n","\n","#Acc\n","from sklearn.metrics import f1_score\n","pred = []\n","gt = []    \n","for cluster in groups:\n","    for food in groups[cluster]:\n","        pred.append(cluster_dict[cluster])\n","        gt.append(food.split('_')[0].split('-')[0])\n","\n","print(\"F1 ACC: \" + str(f1_score(gt, pred,average='micro') * 100))"],"execution_count":null,"outputs":[]}]}